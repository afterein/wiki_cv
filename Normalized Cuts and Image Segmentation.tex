\documentclass[a4paper,10pt]{article}

\usepackage{cmap}
\usepackage{mathtext}
\usepackage[T2A]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage[english,russian]{babel}

\usepackage{amsmath,amsfonts,amssymb,amsthm,mathtools}
\usepackage{icomma}

\DeclareMathOperator{\sgn}{\mathop{sgn}}

\newcommand*{\hm}[1]{#1\nobreak\discretionary{}
{\hbox{$\mathsurround=0pt #1$}}{}}

\usepackage{graphicx}
\graphicspath{{images/}{images2/}}
\setlength\fboxsep{3pt}
\setlength\fboxrule{1pt}
\usepackage{wrapfig}

\usepackage{array,tabularx,tabulary,booktabs}
\usepackage{longtable}
\usepackage{multirow}

\theoremstyle{plain}
\newtheorem{theorem}{Теорема}[section]
\newtheorem{proposition}[theorem]{Утверждение}
 
\theoremstyle{definition}
\newtheorem{corollary}{Следствие}[theorem]
\newtheorem{problem}{Задача}[section]
 
\theoremstyle{remark}
\newtheorem*{nonum}{Решение}

\usepackage{etoolbox}

\usepackage{extsizes}
\usepackage{geometry}
	\geometry{top=15mm}
	\geometry{bottom=15mm}
	\geometry{left=15mm}
	\geometry{right=15mm}
 %
\usepackage{fancyhdr}
 	\renewcommand{\headrulewidth}{0mm}
\usepackage{setspace}

\usepackage{lastpage}

\usepackage{soul}

\usepackage{graphicx}
\usepackage{caption}

\usepackage{hyperref}
\usepackage[usenames,dvipsnames,svgnames,table,rgb]{xcolor}
\hypersetup{
    unicode=true,
    pdftitle={Заголовок},
    pdfauthor={Автор},
    pdfsubject={Тема},
    pdfcreator={Создатель},
    pdfproducer={Производитель},
    pdfkeywords={keyword1} {key2} {key3},
    colorlinks=true,
    linkcolor=red,
    citecolor=green,
    filecolor=magenta,
    urlcolor=blue
}

\usepackage{hyperref}
    \hypersetup{ colorlinks = true, linkcolor = blue }
\usepackage{blindtext}

\usepackage{multicol}
\setcounter{section}{-1}

\usepackage[indentfirst]{titlesec}

\title{Алгоритм нормализованных сечений}
\author{Валентин Леонов (гр. М05-894б)}

\begin{document}

\maketitle

\section{Преамбула}\label{sec:pre}

Граф $\mathbf { G } = ( \mathbf { V } , \mathbf { E } )$ можно разбить на два непересекающихся множества $A , B , A \cup B = V , A \cap B = \emptyset$, удалив ребра, соединяющие эти множества. Степень "непохожести"\ этих двух частей можно вычислить как общий вес удаленных ребер. В теории графов это называется \textit{весом разреза}:
\begin{equation*}
{ cut } ( A , B ) = \sum _ { u \in A , v \in B } w ( u , v )
\end{equation*}

Оптимальное разбиение графа на две части - это то разбиение, которое минимизирует вес разреза. Несмотря на экспоненциальное число таких разбиений, нахождение минимального разреза графа является хорошо изученной задачей, и существуют эффективные алгоритмы для ее решения.

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{fig_1.png}
\caption{\label{fig:cut}Пример случая, когда минимальный разрез дает нам неудачное разбиение графа.}
\end{figure}

Чтобы избежать неестественного "пристастия"\ к отделению небольших наборов вершин, проиллюстрированного на рис.~\ref{fig:cut}, предлагается иная мера "непохожести" . Назовем эту меру \textit{нормализованным сечением}:
\begin{equation*}
{ Ncut } ( A , B ) = \frac { { cut } ( A , B ) } { { assoc } ( A , V ) } + \frac { { cut } ( A , A ) } { { assoc } ( B , V ) },
\end{equation*}
где ${ assoc } ( A , V ) = \sum _ { u \in A , t \in V } w ( u , t )$ - количество ребер между вершинами из $A$ и всеми остальными вершинами графа, а $ { assoc } ( B , V )$ определяется аналогично. С таким определением веса, разрез, который отделяет изолированные вершины, не будет иметь маленькое значение ${Ncut}$.

\section{Введение}

В данном обзоре описан алгоритм субъективной группировки, который нацелен на извлечение глобальных объектов изображения. Рассматривая задачу группировки как задачу разбиения графа, предложен критерий нормализованного сечения.

Нормализованное сечение - это несмещенная мера разбиения графа на подмножества, которая обладает отличным свойством - минимизация нормализованного сечения непосредственно приводит к максимизации нормализованного объединения, которое является несмещенная мерой для объединения в самих подграфах.

Эффективный алгоритм вычисления минимального нормализованного сечения демонстрирует то, что инвариантное подпространство дает решение нашей задачи.

Вычислительный метод, основанный на этой идее, был разработан и применен для сегментации изображений по яркости, цвету и текстуре.

\section{Алгоритм группировки}

\subsection{Общее описание}

\begin{enumerate}
\item Для данного изображения или последовательности изображений строим взвешенный граф $\mathbf { G } = ( \mathbf { V } , \mathbf { E } )$, реберными весами которого будут меры сходства между двумя вершинами.
\item Решаем систему $( \mathbf { D } - \mathbf { W } ) x = \lambda \mathbf { D } x$ для получения собственных векторов с наименьшими собственными значениями.
\item Используя собственный вектор (\href{https://ru.wikipedia.org/wiki/%D0%90%D0%BB%D0%B3%D0%B5%D0%B1%D1%80%D0%B0%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B0%D1%8F_%D1%81%D0%B2%D1%8F%D0%B7%D0%BD%D0%BE%D1%81%D1%82%D1%8C#%D0%92%D0%B5%D0%BA%D1%82%D0%BE%D1%80_%D0%A4%D0%B8%D0%B4%D0%BB%D0%B5%D1%80%D0%B0}{вектор Фидлера}) со вторым из минимальных собственных значений, разделяем граф на две части.
\item При необходимости рекурсивно разбиваем получившиеся части.
\end{enumerate}

Полробное описание алгоритма группировки, а также его вычислительную сложность можно проиллюстрировать на следующем примере.

\begin{figure}
\centering
\includegraphics[width=0.3\textwidth]{fig_2.png}
\caption{\label{fig:baseball}Серое изображение для обработки.}
\end{figure}

\subsection{Описание алгоритма, использующего яркость изображения}

На рис.~\ref{fig:baseball} показано изображение, которое мы хотели бы сегментировать. Описание шагов алгоритма:

\begin{figure}
\centering
\includegraphics[width=0.5\textwidth]{fig_3.png}
\centering
\captionsetup{justification=centering}
\caption{\label{fig:eigenvectors}(а) наименьшие собственные векторы. (b) - (i) собственные векторы, соответствующие наименьшим собственным значениям (со второго по девятое).}
\end{figure}

\begin{enumerate}
\item Строим взвешенный граф $\mathbf { G } = ( \mathbf { V } , \mathbf { E } )$, сопоставив каждый пиксель с вершиной графа и соединив каждую пару пикселей ребром. Вес на этом ребре должен отражать вероятность того, что два пикселя принадлежат одному объекту. Используя только значение яркости пикселей $\mathbf { F }$ и их пространственное расположение $\mathbf { X }$, мы можем определить вес ребра, соединяющего вершины $i$ и $j$, как:
\begin{equation*}
w _ { i j } = e ^ { \frac { - \left\| \mathbf {F} _ { ( i ) } - \mathbf {F} _ { ( j ) } \right\| _ { 2 } ^ { 2 } } { \sigma _ { I } ^ { 2 } } } * \left\{ \begin{array} { l l } { e ^ { \frac { - \left\| \mathbf {X} _ { ( i ) } - \mathbf {X} _ { ( j ) } \right\| _ { 2 } ^ { 2 } } { \sigma _ { X } ^ { 2 } } } } & { \text { если } \| \mathbf {X} ( i ) - \mathbf {X} ( j ) \| _ { 2 } < r } \\ { 0 } & { \text { в противном случае. } } \end{array} \right.
\end{equation*}
\item Сводим систему
\begin{equation*}
( \mathbf { D } - \mathbf { W } ) \boldsymbol { y } = \lambda \mathbf { D } y
\end{equation*}
к стандартной задаче вычисления собственных значений
\begin{equation*}
\mathbf { D } ^ { - \frac { 1 } { 2 } } ( \mathbf { D } - \mathbf { W } ) \mathbf { D } ^ { - \frac { 1 } { 2 } } \boldsymbol { x } = \lambda x
\end{equation*}
и получаем собственные вектора с наименьшими собственными значениями.
Решение задачи вычисления собственных значений для всех собственных векторов требует $\mathcal{O}(n ^ 3)$ операций, где $n$ - количество вершин в графе. Это слишком медленно для задачи сегментации изображения, где $n$ - это количество пикселей в изображении.
К счастью, наше разбиение графа имеет следующие свойства:
    \begin{enumerate}
        \item Подграфы чаще всего связаны только локально, и полученные системы довольно разрежены.
        \item Для разбиения графа достаточно всего нескольких собственных векторов.
        \item Требуется низкая точность для собственных векторов, часто нужен лишь знак.
    \end{enumerate}
Данные свойства позволяют воспользоваться методом Ланцоша. Временная сложность алгоритма Ланцоша составляет $\mathcal{O}(mn) + \mathcal{O}(m \mathcal{M}(n))$, где $m$ - максимальное количество требуемых умножений матрицы на вектор, а $\mathcal{M}(n)$ - стоимость вычисления матрицы $\mathbf {A} x$, где $\mathbf {A} = \mathbf {D} ^ {-\frac {1} {2} } ( \mathbf {D} - \mathbf {W} ) \mathbf {D} ^ {-\frac {1} {2} }$. А поскольку матрица весов $\mathbf {W}$ и матрица $\mathbf {A}$ разрежены, умножение происходит за $\mathcal{O}(n)$.

Чтобы понять, почему это так, рассмотрим стоимость скалярного произведения одной строки $\mathbf { A }$ с вектором $\mathbf { x }$. Пусть $\mathbf { y } _ { i } = A _ { i } \cdot \mathbf { x } = \sum _ { j } \boldsymbol { A } _ { i j } \mathbf { x } _ { j }$. Для фиксированого $i$, $\boldsymbol { A } _ { i j }$ не равно нулю, только если вершина $j$ находится в пространственной окрестности вершины $i$. Следовательно, для вычисления $\boldsymbol {A} _ { i } \cdot \mathbf { x }$ требуется фиксированное число операций, а общая стоимость вычисления $\boldsymbol{A} \mathbf { x }$ составляет $\mathcal{O}(n)$.

\begin{figure}
\centering
\includegraphics[width=0.7\textwidth]{fig_4.png}
\captionsetup{justification=centering}
\caption{\label{fig:segments}(а) исходное изображение размером $80 \times 100$. (b) - (h) сегменты изображения,
для значения $Ncut$ менее 0,04. Значения параметров: $\sigma _ { I } = 0.1 , \sigma _ { X } = 4.0 , r = 5$.}
\end{figure}

Внеасимптотическая константа определяется алгебраической связностью графа. Оказывается, мы можем существенно сократить количество ребер от каждой вершины к смежным с ней путем случайного удаления этих ребер в некоторой окрестности вершины. Опытным путем было обнаружено, что можно удалить до 90\% всех ребер в большой окрестности вершины, не влияя при этам на собственные векторы системы.

В конечном итоге, каждое из произведений матрицы на вектор стоит $\mathcal{O}(n)$ операций с небольшой константой. Число $m$ зависит от многих факторов. В экспериментах по сегментации изображений оказывалось, что $m$ обычно меньше $\mathcal{O}(n ^ \frac{1}{2})$.
\item После вычисления собственных векторов мы можем разбить граф на две части, используя второй из наименьших собственных векторов. В идеальном мире собственный вектор будет состоять их двух целых значений, а их знаки точно скажут нам, как разбить граф. Однако наши собственные векторы могут принимать вещественные значения, и нам нужно выбрать точку разделения, чтобы разделить граф на две части. Есть много разных способов выбора такой точки. Можно взять 0 или медиану в качестве точки разделения, или можно искать ее так, чтобы результирующее разделение имело наилучшее значение \hyperref[sec:pre]{$Ncut ( A , B )$}.
\item После того, как граф разбит на две части, мы можем рекурсивно запустить наш алгоритм на этих частях. Или, что эквивалентно, мы могли бы воспользоваться особыми свойствами других наименьших собственных векторов, чтобы разделить граф с их помощью. Рекурсия останавливается, как только значение $Ncut$ превышает определенный предел.
\end{enumerate}

\nocite{*}
\bibliographystyle{plain}
\bibliography{bibliography}

\end{document}
